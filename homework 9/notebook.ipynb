{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f21278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "input tensor_type {\n",
      "  elem_type: 1\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_param: \"s77\"\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 3\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 200\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 200\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "Outputs:\n",
      "output tensor_type {\n",
      "  elem_type: 1\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_param: \"s77\"\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "ONNXRuntime outputs:\n",
      "output ['s77', 1] tensor(float)\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "model_path = \"hair_classifier_v1.onnx\"\n",
    "\n",
    "# Opción 1: con onnx\n",
    "model = onnx.load(model_path)\n",
    "graph = model.graph\n",
    "\n",
    "print(\"Inputs:\")\n",
    "for i in graph.input:\n",
    "    print(i.name, i.type)\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "for o in graph.output:\n",
    "    print(o.name, o.type)\n",
    "\n",
    "# Opción 2: con onnxruntime\n",
    "session = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "print(\"\\nONNXRuntime outputs:\")\n",
    "for o in session.get_outputs():\n",
    "    print(o.name, o.shape, o.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd75561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.23921569)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    return Image.open(BytesIO(buffer))\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img.resize(target_size, Image.NEAREST)\n",
    "\n",
    "url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "\n",
    "img = download_image(url)\n",
    "img = prepare_image(img, (200, 200))\n",
    "\n",
    "x = np.array(img).astype(\"float32\") / 255.0\n",
    "\n",
    "x_nchw = np.transpose(x, (2, 0, 1))\n",
    "x_nchw = np.expand_dims(x_nchw, 0)\n",
    "\n",
    "first_pixel_R = x_nchw[0, 0, 0, 0]\n",
    "first_pixel_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241e2be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9217668771743774"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    return Image.open(BytesIO(buffer))\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img.resize(target_size, Image.NEAREST)\n",
    "\n",
    "url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "\n",
    "# Preprocesar imagen\n",
    "img = download_image(url)\n",
    "img = prepare_image(img, (200, 200))\n",
    "\n",
    "x = np.array(img).astype(\"float32\") / 255.0\n",
    "x = np.transpose(x, (2, 0, 1))\n",
    "x = np.expand_dims(x, 0)\n",
    "\n",
    "# Cargar modelo ONNX\n",
    "session = ort.InferenceSession(\"hair_classifier_v1.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "pred = session.run([output_name], {input_name: x})[0]\n",
    "score = float(pred.flatten()[0])\n",
    "score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
